name: Build packages with Pyodide

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  run_build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          # - repo: https://github.com/Pylons/paginate
          #   name: paginate
          #   version: "0.5.6"
          # - repo: https://github.com/gorakhargosh/watchdog
          #   name: watchdog
          #   version: "v2.3.1"
          # - repo: https://github.com/gorakhargosh/watchdog
          #   name: watchdog
          #   version: "v3.0.0"
          # - repo: https://github.com/kuelumbus/rdkit-pypi/
          #   name: rdkit-pypi
          #   version: "rdkit-pypi"
          - repo: https://github.com/pytorch/pytorch
            name: pytorch
            package-name: pytorch
            version: "v1.13.1"

    steps:
      - name: Check out the repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11.2

      - name: Set up env vars for Emscripten
        run: |
          set -vxeuo pipefail
          pip install pyodide-build>=0.23.0
          export EMSCRIPTEN_VERSION=$(pyodide config get emscripten_version)
          echo EMSCRIPTEN_VERSION=${EMSCRIPTEN_VERSION} >> $GITHUB_ENV
          echo "EMSCRIPTEN_VERSION is $EMSCRIPTEN_VERSION"

      - name: Set up Emscripten
        uses: mymindstorm/setup-emsdk@v14
        with:
          version: ${{ env.EMSCRIPTEN_VERSION }}

      - name: Build with Pyodide
        run: |
          set -vxeo pipefail
          git clone --depth 1 --branch ${{ matrix.version }} ${{ matrix.repo }}
          cd ${{ matrix.name }}

          # CF build script: https://github.com/conda-forge/pytorch-cpu-feedstock/blob/main/recipe/build.sh
          # remove pyproject.toml to avoid installing deps from pip
          rm -rf pyproject.toml

          # uncomment to debug cmake build
          # export CMAKE_VERBOSE_MAKEFILE=1

          export USE_NUMA=0
          export USE_ITT=0
          export CFLAGS="$(echo $CFLAGS | sed 's/-fvisibility-inlines-hidden//g')"
          export CXXFLAGS="$(echo $CXXFLAGS | sed 's/-fvisibility-inlines-hidden//g')"
          export LDFLAGS="$(echo $LDFLAGS | sed 's/-Wl,--as-needed//g')"
          export LDFLAGS="$(echo $LDFLAGS | sed 's/-Wl,-dead_strip_dylibs//g')"
          export LDFLAGS_LD="$(echo $LDFLAGS_LD | sed 's/-dead_strip_dylibs//g')"
          if [[ "$c_compiler" == "clang" ]]; then
              export CXXFLAGS="$CXXFLAGS -Wno-deprecated-declarations -Wno-unknown-warning-option -Wno-error=unused-command-line-argument"
              export CFLAGS="$CFLAGS -Wno-deprecated-declarations -Wno-unknown-warning-option -Wno-error=unused-command-line-argument"
          else
              export CXXFLAGS="$CXXFLAGS -Wno-deprecated-declarations -Wno-error=maybe-uninitialized"
              export CFLAGS="$CFLAGS -Wno-deprecated-declarations -Wno-error=maybe-uninitialized"
          fi

          # This is not correctly found for linux-aarch64 since pytorch 2.0.0 for some reason
          export _GLIBCXX_USE_CXX11_ABI=1

          # KINETO seems to require CUPTI and will look quite hard for it.
          # CUPTI seems to cause trouble when users install a version of
          # cudatoolkit different than the one specified at compile time.
          # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/135
          export USE_KINETO=OFF

          if [[ "$target_platform" == "osx-64" ]]; then
            export CXXFLAGS="$CXXFLAGS -DTARGET_OS_OSX=1"
            export CFLAGS="$CFLAGS -DTARGET_OS_OSX=1"
          fi

          # Dynamic libraries need to be lazily loaded so that torch
          # can be imported on system without a GPU
          LDFLAGS="${LDFLAGS//-Wl,-z,now/-Wl,-z,lazy}"

          export CMAKE_GENERATOR=Ninja
          export CMAKE_LIBRARY_PATH=$PREFIX/lib:$PREFIX/include:$CMAKE_LIBRARY_PATH
          export CMAKE_PREFIX_PATH=$PREFIX
          export CMAKE_BUILD_TYPE=Release

          for ARG in $CMAKE_ARGS; do
            if [[ "$ARG" == "-DCMAKE_"* ]]; then
              cmake_arg=$(echo $ARG | cut -d= -f1)
              cmake_arg=$(echo $cmake_arg| cut -dD -f2-)
              cmake_val=$(echo $ARG | cut -d= -f2-)
              printf -v $cmake_arg "$cmake_val"
              export ${cmake_arg}
            fi
          done
          unset CMAKE_INSTALL_PREFIX
          export TH_BINARY_BUILD=1
          export PYTORCH_BUILD_VERSION=$PKG_VERSION
          export PYTORCH_BUILD_NUMBER=$PKG_BUILDNUM

          export INSTALL_TEST=0
          export BUILD_TEST=0

          export USE_SYSTEM_SLEEF=1
          # use our protobuf
          export BUILD_CUSTOM_PROTOBUF=OFF
          rm -rf $PREFIX/bin/protoc

          if [[ "${target_platform}" != "${build_platform}" ]]; then
              # It helps cross compiled builds without emulation support to complete
              # Use BUILD PREFIX protoc instead of the one that is from the host platform
              sed -i.bak \
                  "s,IMPORTED_LOCATION_RELEASE .*/bin/protoc,IMPORTED_LOCATION_RELEASE \"${BUILD_PREFIX}/bin/protoc," \
                  ${PREFIX}/lib/cmake/protobuf/protobuf-targets-release.cmake
          fi

          # I don't know where this folder comes from, but it's interfering with the build in osx-64
          rm -rf $PREFIX/git

          if [[ "$CONDA_BUILD_CROSS_COMPILATION" == 1 ]]; then
              export COMPILER_WORKS_EXITCODE=0
              export COMPILER_WORKS_EXITCODE__TRYRUN_OUTPUT=""
          fi

          export MAX_JOBS=${CPU_COUNT}

          if [[ "$blas_impl" == "generic" ]]; then
              # Fake openblas
              export BLAS=OpenBLAS
              sed -i.bak "s#FIND_LIBRARY.*#set(OpenBLAS_LIB ${PREFIX}/lib/liblapack${SHLIB_EXT} ${PREFIX}/lib/libcblas${SHLIB_EXT} ${PREFIX}/lib/libblas${SHLIB_EXT})#g" cmake/Modules/FindOpenBLAS.cmake
          else
              export BLAS=MKL
          fi

          if [[ "$PKG_NAME" == "pytorch" ]]; then
            PIP_ACTION=install
            sed "s/3.12/$PY_VER/g" build/CMakeCache.txt.orig > build/CMakeCache.txt
          else
            # For the main script we just build a wheel for so that the C++/CUDA
            # parts are built. Then they are reused in each python version.
            PIP_ACTION=wheel
          fi

          # MacOS build is simple, and will not be for CUDA
          if [[ "$OSTYPE" == "darwin"* ]]; then
              # Produce macOS builds with torch.distributed support.
              # This is enabled by default on Linux, but disabled by default on macOS,
              # because it requires an non-bundled compile-time dependency (libuv
              # through gloo). This dependency is made available through meta.yaml, so
              # we can override the default and set USE_DISTRIBUTED=1.
              export USE_DISTRIBUTED=1

              if [[ "$target_platform" == "osx-arm64" ]]; then
                  # MKLDNN did not support on Apple M1 at the time support Apple M1
                  # was added. Revisit later
                  export USE_MKLDNN=0
              fi
          elif [[ ${cuda_compiler_version} != "None" ]]; then
              # Even though cudnn is used for CUDA builds, it's good to enable
              # for MKLDNN for CUDA builds when CUDA builds are used on a machine
              # with no NVIDIA GPUs. However compilation fails with mkldnn and cuda enabled.
              export USE_MKLDNN=OFF
              export USE_CUDA=1
              if [[ ${cuda_compiler_version} == 9.0* ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;7.0+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 9.2* ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 10.* ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 11.0* ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5;8.0+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 11.1 ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 11.2 ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 11.8 ]]; then
                  export TORCH_CUDA_ARCH_LIST="3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6;8.9+PTX"
                  export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME
              elif [[ ${cuda_compiler_version} == 12.0 ]]; then
                  export TORCH_CUDA_ARCH_LIST="5.0;6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0+PTX"
                  # $CUDA_HOME not set in CUDA 12.0. Using $PREFIX
                  export CUDA_TOOLKIT_ROOT_DIR="${PREFIX}"
              else
                  echo "unsupported cuda version. edit build_pytorch.sh"
                  exit 1
              fi
              export TORCH_NVCC_FLAGS="-Xfatbin -compress-all"
              export NCCL_ROOT_DIR=$PREFIX
              export NCCL_INCLUDE_DIR=$PREFIX/include
              export USE_SYSTEM_NCCL=1
              export USE_STATIC_NCCL=0
              export USE_STATIC_CUDNN=0
              export MAGMA_HOME="${PREFIX}"
          else
              if [[ "$target_platform" != *-64 ]]; then
                # Breakpad seems to not work on aarch64 or ppc64le
                # https://github.com/pytorch/pytorch/issues/67083
                export USE_BREAKPAD=0
              fi
              # MKLDNN is an Apache-2.0 licensed library for DNNs and is used
              # for CPU builds. Not to be confused with MKL.
              export USE_MKLDNN=1
              export CMAKE_TOOLCHAIN_FILE="${RECIPE_DIR}/cross-linux.cmake"
          fi

          export USE_CUDA=0
          echo '${CXX}'=${CXX}
          echo '${PREFIX}'=${PREFIX}
          # End of CF build script
          pyodide build
          ls -la
          tree .

      - name: Upload built artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.package-name }}-${{ matrix.version }}
          path: ${{ matrix.name }}/dist/${{ matrix.package-name }}-*.whl
